# TikTok Toxicity Monitoring - Kiáº¿n TrÃºc Lambda

Dá»± Ã¡n phÃ¢n tÃ­ch Ä‘á»™c tÃ­nh (toxicity/hate speech) trÃªn dá»¯ liá»‡u TikTok sá»­ dá»¥ng kiáº¿n trÃºc Lambda vá»›i Apache Spark, Kafka vÃ  PostgreSQL.

## ğŸš€ Quick Start vá»›i UV

### 1. CÃ i Ä‘áº·t UV (náº¿u chÆ°a cÃ³)

```bash
# MacOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Hoáº·c vá»›i Homebrew
brew install uv

# Kiá»ƒm tra
uv --version
```

### 2. Setup Environment

```bash
# Clone project
git clone <repo-url>
cd tiktok-lambda-toxicity

# Táº¡o virtual environment vÃ  install dependencies
uv venv .venv
source .venv/bin/activate  # hoáº·c ./activate.sh
uv pip install -r requirements.txt

# Hoáº·c sá»­ dá»¥ng script
./activate.sh
```

### 3. Start Infrastructure

```bash
# Start Kafka + PostgreSQL + Kafka UI
docker compose up -d

# Initialize database
./scripts/init_db.sh
```

### 4. Test Pipeline

```bash
# Generate sample data
uv run python scripts/generate_sample_data.py

# Run ingestion (Kafka Producer)
uv run python src/ingestion/json_to_kafka.py

# Run speed layer (Streaming)
./scripts/start_streaming.sh

# Query results
psql -h localhost -U tiktok_user -d tiktok_toxicity
SELECT * FROM serving_video_stats LIMIT 5;
```

## ğŸ—ï¸ Kiáº¿n TrÃºc

```mermaid
graph TD
    %% Source
    S3["ğŸ“¦ AWS S3 (Raw Data)<br/>LÆ°u trá»¯ file JSON/JSONL"]
    
    %% Ingestion
    S3 --> KAFKA["ğŸš€ Apache Kafka<br/>Há»‡ thá»‘ng truyá»n tin (Message Broker)"]
    
    %% Split to Lambda
    KAFKA --> SPEED["âš¡ Speed Layer (Spark Streaming)<br/>Xá»­ lÃ½ Real-time (cá»­a sá»• 5 phÃºt)"]
    KAFKA --> BATCH["ğŸ“š Batch Layer (Spark Batch)<br/>Xá»­ lÃ½ Ä‘á»‹nh ká»³ toÃ n bá»™ dá»¯ liá»‡u"]
    
    %% Analysis in Layers
    subgraph Analysis ["AI & PhÃ¢n tÃ­ch"]
        SPEED --- MODEL["ğŸ§  Model ViHateT5<br/>PhÃ¡t hiá»‡n Ä‘á»™c háº¡i ngay láº­p tá»©c"]
        BATCH --- DEEP["ğŸ” PhÃ¢n tÃ­ch sÃ¢u<br/>Gom nhÃ³m ngÆ°á»i dÃ¹ng & Hashtag"]
    end
    
    %% Database
    SPEED --> DB[("ğŸ’¾ PostgreSQL (Serving Layer)<br/>LÆ°u trá»¯ báº£ng Speed & Batch")]
    BATCH --> DB
    
    %% Unified View
    DB --> VIEW["ğŸ‘ï¸ SQL Views<br/>Gá»™p dá»¯ liá»‡u Real-time + Historical"]
    
    %% Visualization
    VIEW --> TABLEAU["ğŸ“Š Tableau Dashboard<br/>Hiá»ƒn thá»‹ bÃ¡o cÃ¡o & Cáº£nh bÃ¡o"]

    %% Styling
    style S3 fill:#f9f,stroke:#333,stroke-width:2px
    style KAFKA fill:#bbf,stroke:#333,stroke-width:2px
    style SPEED fill:#ff9,stroke:#333,stroke-width:2px
    style BATCH fill:#9f9,stroke:#333,stroke-width:2px
    style DB fill:#f96,stroke:#333,stroke-width:2px
    style TABLEAU fill:#3cf,stroke:#333,stroke-width:4px
```

### Lambda Architecture Components

1. **Ingestion Layer**: Äá»c file JSON/JSONL â†’ Kafka topic `tiktok-raw`
2. **Speed Layer**: Spark Structured Streaming â†’ xá»­ lÃ½ realtime (window 5 phÃºt)
3. **Batch Layer**: Spark Batch job cháº¡y hÃ ng ngÃ y lÃºc 2h sÃ¡ng (cron)
4. **Serving Layer**: PostgreSQL views merge batch + speed data
5. **Model**: ViHateT5-HSD (Vietnamese Hate Speech Detection)

## ğŸ“ Cáº¥u TrÃºc ThÆ° Má»¥c

```
tiktok-lambda-toxicity/
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml          # UV project config
â”œâ”€â”€ uv.lock                # UV lock file
â”œâ”€â”€ requirements.txt        # Legacy pip requirements
â”œâ”€â”€ activate.sh            # Activate virtual environment
â”œâ”€â”€ deactivate.sh          # Deactivate virtual environment
â”œâ”€â”€ docker-compose.yml      # Infrastructure setup
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml         # Application config
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â””â”€â”€ json_to_kafka.py     # Kafka Producer
â”‚   â”œâ”€â”€ speed_layer/
â”‚   â”‚   â””â”€â”€ streaming_toxicity.py # Spark Streaming
â”‚   â”œâ”€â”€ batch_layer/
â”‚   â”‚   â””â”€â”€ batch_full_recompute.py # Spark Batch
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ toxicity_detector.py  # ViHateT5 wrapper
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ db_utils.py           # PostgreSQL utilities
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_sample_data.py   # Sample data generator
â”‚   â”œâ”€â”€ start_streaming.sh        # Start Speed Layer
â”‚   â”œâ”€â”€ run_batch.sh              # Run Batch Layer
â”‚   â”œâ”€â”€ setup_cron.sh             # Setup cron job
â”‚   â””â”€â”€ init_db.sh                # Initialize database
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ serving_views.sql         # PostgreSQL schema + views
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Input JSONL files
â”‚   â”œâ”€â”€ processed/                # Processed files
â”‚   â”œâ”€â”€ failed/                   # Failed files
â”‚   â””â”€â”€ archive/                  # Historical data
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ speed/                    # Speed Layer checkpoints
â”‚   â””â”€â”€ batch/                    # Batch Layer checkpoints
â””â”€â”€ .venv/                        # UV virtual environment
```

## ğŸ› ï¸ Development vá»›i UV

### Lá»‡nh UV phá»• biáº¿n

```bash
# Táº¡o virtual environment
uv venv .venv

# Activate environment
source .venv/bin/activate
# hoáº·c ./activate.sh

# Install dependencies
uv pip install -r requirements.txt

# Add new dependency
uv pip install package-name

# Install from pyproject.toml
uv pip install -e .

# Run scripts
uv run python scripts/generate_sample_data.py

# Upgrade dependencies
uv pip install --upgrade transformers torch

# Show installed packages
uv pip list

# Export requirements (náº¿u cáº§n)
uv pip freeze > requirements.txt

# Deactivate
deactivate
# hoáº·c ./deactivate.sh
```

### So sÃ¡nh UV vs pip/venv

| Feature | UV | pip + venv |
|---------|----|------------|
| **Speed** | âš¡ **Very fast** | ğŸŒ Slow |
| **Disk usage** | ğŸ“¦ **Shared cache** | ğŸ’¾ Duplicate packages |
| **Commands** | ğŸ”§ Few commands | ğŸ“š Many tools |
| **Lock file** | âœ… Automatic | âŒ Manual |
| **Reproducibility** | âœ… Excellent | âš ï¸ Good |

## ğŸš€ CÃ´ng Nghá»‡

- **Python 3.8+**
- **Apache Spark 3.5+** (Structured Streaming + Batch)
- **Apache Kafka** (Message broker)
- **PostgreSQL** (Serving database)
- **Hugging Face Transformers** (ViHateT5-HSD model)
- **UV** (Fast Python package manager)
- **Docker Compose** (Dev environment)

## ğŸ”§ CÃ i Äáº·t

### Setup vá»›i UV (Khuyáº¿n nghá»‹)

```bash
# 1. Install UV
curl -LsSf https://astral.sh/uv/install.sh | sh

# 2. Clone vÃ  setup
git clone <repo-url>
cd tiktok-lambda-toxicity

# 3. Create environment vÃ  install
uv venv .venv
source .venv/bin/activate
uv pip install -r requirements.txt

# 4. Start infrastructure
docker compose up -d

# 5. Initialize database
./scripts/init_db.sh
```

### Setup vá»›i pip (Traditional)

```bash
# 1. Create venv
python3 -m venv venv
source venv/bin/activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Continue with steps 4-5 above
```

## ğŸ“Š Sá»­ Dá»¥ng

### 1. Generate Sample Data

```bash
uv run python scripts/generate_sample_data.py
```

### 2. Run Ingestion Layer

```bash
uv run python src/ingestion/json_to_kafka.py
```

### 3. Run Speed Layer

```bash
./scripts/start_streaming.sh
```

### 4. Run Batch Layer

```bash
./scripts/run_batch.sh
```

### 5. Query Serving Views

```bash
psql -h localhost -U tiktok_user -d tiktok_toxicity
SELECT * FROM serving_video_stats LIMIT 10;
```

## ğŸ“ˆ Serving Layer Views

### CÃ¡c Views cho Power BI

1. **`serving_video_stats`** - Merge batch + speed data cho video statistics
2. **`serving_hashtag_stats`** - Hashtag controversy ranking
3. **`serving_user_ranking`** - Top toxic users
4. **`serving_alerts`** - Real-time alerts (toxic_ratio > 0.7)
5. **`serving_top_toxic_videos`** - Top 100 toxic videos
6. **`serving_recent_activity`** - Last 24h summary

### Power BI Connection

```
Host: localhost
Port: 5432
Database: tiktok_toxicity
Username: powerbi_reader
Password: powerbi_read123
```

## ğŸ§ª Testing

### Test Toxicity Detector

```bash
uv run python src/models/toxicity_detector.py
```

### Test Database Connection

```bash
uv run python src/utils/db_utils.py
```

### Monitor Kafka Topics

```bash
# List topics
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --list

# Consume messages
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic tiktok-raw \
  --from-beginning
```

## ğŸ“Š Schema

### Input JSON Schema

```json
{
  "video_id": "video_12345",
  "caption": "Chia sáº» máº¹o náº¥u Äƒn",
  "comments": [
    {
      "user_id": "user_001",
      "text": "Hay quÃ¡ báº¡n Æ¡i!",
      "created_at": "2024-01-01T10:00:00"
    }
  ],
  "hashtags": ["cooking", "food", "recipe"],
  "created_at": "2024-01-01T09:00:00"
}
```

### Output Tables

#### Speed Layer Tables
- `speed_video_stats` - Window-based video statistics
- `speed_alerts` - High toxicity alerts

#### Batch Layer Tables
- `batch_video_stats` - Historical video statistics
- `batch_hashtag_stats` - Hashtag statistics
- `batch_user_ranking` - User toxicity ranking

## ğŸ” Monitoring

### Spark UI
- Speed Layer: http://localhost:4040
- Batch Layer: http://localhost:4040

### Kafka UI
- URL: http://localhost:8080
- Browse topics, messages, consumers

## âš™ï¸ Configuration

Chá»‰nh sá»­a `config/config.yaml`:

```yaml
kafka:
  bootstrap_servers: "localhost:9092"
  topic_raw: "tiktok-raw"

postgres:
  host: "localhost"
  port: 5432
  database: "tiktok_toxicity"

model:
  name: "tarudesu/ViHateT5-HSD"
  device: "cpu"  # hoáº·c "cuda" náº¿u cÃ³ GPU

speed_layer:
  window_duration: "5 minutes"
  toxic_threshold: 0.4
```

## ğŸ› Troubleshooting

### Lá»—i Kafka Connection

```bash
# Check services
docker compose ps

# Restart if needed
docker compose restart
```

### Lá»—i PostgreSQL Connection

```bash
# Check PostgreSQL
docker compose ps postgres
docker compose logs postgres

# Test connection
psql -h localhost -U tiktok_user -d tiktok_toxicity
```

### Lá»—i Model Loading

Láº§n Ä‘áº§u cháº¡y sáº½ download model (~500MB). Cáº§n internet connection.

### Lá»—i Checkpoint

```bash
# Clear checkpoints
rm -rf checkpoints/speed/*
rm -rf checkpoints/batch/*
```

## ğŸ’¡ Tips

- Speed Layer cáº§n ~2GB RAM
- Batch Layer cáº§n ~4GB RAM
- Model inference nhanh hÆ¡n vá»›i GPU (CUDA)
- Use Parquet format cho archive data (nhanh hÆ¡n JSON)

## ğŸ“ TODO / Future Improvements

- [ ] Add ONNX model support cho faster inference
- [ ] Implement Kubernetes deployment
- [ ] Add Grafana dashboards
- [ ] Implement data retention policies
- [ ] Add API layer (FastAPI)
- [ ] Implement A/B testing for different models
- [ ] Add data quality checks
- [ ] Build admin dashboard

## ğŸ“„ License

MIT License

## ğŸ‘¥ Contributors

- [Your Name]

## ğŸ“š References

- [ViHateT5-HSD Model](https://huggingface.co/tarudesu/ViHateT5-HSD)
- [Apache Spark Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [Lambda Architecture](http://lambda-architecture.net/)
- [UV Documentation](https://docs.astral.sh/uv/)