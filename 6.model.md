# src/models/toxicity_detector.py

Tạo class ToxicityDetector:
- Load model tarudesu/ViHateT5-HSD (hoặc fallback detoxify nếu cần)
- Hàm predict(text: str) → label ("HATE", "OFFENSIVE", "CLEAN")
- Hàm predict_batch(list[text]) → list[label]
- Hỗ trợ ONNX nếu có thể (tùy chọn)
- Có caching tokenizer/model
- Dùng trong Spark UDF hoặc Pandas UDF