# src/batch_layer/batch_full_recompute.py

Viết Spark Batch job (không streaming):
- Đọc toàn bộ dữ liệu từ data lake (Parquet hoặc JSON trong HDFS/S3/local /data/archive)
- Hoặc đọc lại từ Kafka từ offset earliest (nếu lưu retention lâu)
- Xử lý tương tự Speed Layer: explode comments → detect toxicity bằng ViHateT5
- Aggregate toàn bộ lịch sử:
  - Per video_id: total/toxic comments/ratio
  - Per hashtag: top controversial
  - Per user: top toxic users (count toxic comments)
- Ghi ĐÈ (overwrite) vào các table PostgreSQL:
  - batch_video_stats
  - batch_hashtag_stats
  - batch_user_ranking
- Chạy hàng ngày lúc 2h sáng bằng cron